{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2537a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#실제 그래프를 그릴 수 있는 서브 함수\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#경고표시 생략(일시적으로 생략하는게 좋음) \n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "#한글폰트 지정 \n",
    "import matplotlib.font_manager as fm\n",
    "font_name= fm.FontProperties(fname=\"C:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "plt.rc(\"font\",family=font_name)\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.unicode_minus']=False\n",
    "\n",
    "# 머신러닝을 위한 모듈 \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf88b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## 더 간단하게 쓰기 --> keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64632489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간의 흐름에 따라 지금 단어와 이전 단어를 알아야 함. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207692af",
   "metadata": {},
   "source": [
    "## 1. 정의\n",
    "\n",
    "+ 시계열 데이터와 같이 시간의 흐름에 따라 변화하는 데이터를 학습하기 위한 딥러닝 모델 \n",
    "\n",
    "+ 기준 시점(t)과 다음 시점(t+1)에 네트워크를 연결하여 구성한 인공신경망\n",
    "\n",
    "## 2. 의의\n",
    "\n",
    "+ '그는 그녀에게 사과의 의미로 빨간 사과 한 바구니를 건내주며 미안하다고 말했다.'  --> 문장에 대한 전처리가 필요함. \n",
    "\n",
    "+ 위의 문장과 같이 단순한 사전적 의미 뿐만 아니라, 앞 뒤 문장의 요소들을 종합적으로 판단하여 의미를 파악하고 해석. \n",
    "\n",
    "## 3. 자연어 처리(NLP)\n",
    "\n",
    "+ Thesaurus : 유의어 사전 --> 비슷한 단어들은 사전으로 만들어 참고, 가장 쉽고 간단한 방법\n",
    "    - < 단점 >\n",
    "    - 시대변화에 대응하기가 어렵다. \n",
    "    - 단어의 미묘한 차이를 표현하기 어렵 --> 융통성을 발휘하기 힘듦. \n",
    "    \n",
    "+ 통계 기반 기법\n",
    "    - 어떤 단어가 주목했을 때 그 주변에 어떤 단어가 몇번 등장했는지를 세어 집계하는 방법 \n",
    "    - 데이터가 많이 커짐 --> 거대 행렬 발생\n",
    "\n",
    "+ 추론 기반 기법 : Word2Vec -> 단어를 벡터화 시키겠다(행렬로)\n",
    "    - 유사도 측정가능 \n",
    "    - gensin -- > 유사도 측정\n",
    "    - 엄청난 데이터가 필요함 \n",
    "    \n",
    "## 4. 두가지 결과 \n",
    "\n",
    "+ 다중 분류 --> 위쪽으로 분류 \n",
    "    - 품사 분류 \n",
    "        e.g. I google at work 나는 일할 때 구글링한다.\n",
    "             I work at google 나는 구글에서 일한다. \n",
    "             --> 품사를 알아야 구분 가능 \n",
    "+ 이진 분류 \n",
    "    - 감정 분석할 때 - 화났냐 안났냐 \n",
    "        e.g. traffic tiket fines \n",
    "             traffic is fine \n",
    "             \n",
    "## 5. 종류\n",
    "\n",
    "+ Vanilla RNN\n",
    "+ LSTM --> 실제로 많이 쓰임 \n",
    "    - tanh - 탄젠트 h \n",
    "    - 이전 기억을 계속 곱하는 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff84aa73",
   "metadata": {},
   "source": [
    "## 6. 실습(Vanilla RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742ee287",
   "metadata": {},
   "source": [
    "### (1) 단일 cell을 통한 계산 처리 과정: 기본 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9563ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 입력 데이터 : 1 행 2열 \n",
    "\n",
    "inputs= np.array([[[1,2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e0a94a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_27488/592030655.py:5: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_27488/592030655.py:6: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_27488/592030655.py:11: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_27488/592030655.py:13: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 3), dtype=float32)\n",
      "Tensor(\"rnn/while/Exit_3:0\", shape=(1, 3), dtype=float32)\n",
      "\n",
      " Weights\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_27488/592030655.py:18: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_27488/592030655.py:18: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "<tf.Variable 'rnn/basic_rnn_cell/kernel:0' shape=(5, 3) dtype=float32_ref>\n",
      "<tf.Variable 'rnn/basic_rnn_cell/bias:0' shape=(3,) dtype=float32_ref>\n",
      "---------------------------------------------------------\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_27488/592030655.py:23: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_27488/592030655.py:24: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "output values\n",
      "[[[-0.9314169   0.75578666 -0.6819246 ]]]\n",
      "Wnstate value\n",
      "[[-0.9314169   0.75578666 -0.6819246 ]]\n",
      "WnWeights\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_27488/592030655.py:34: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "rnn/basic_rnn_cell/kernel:0 [[-0.62831575  0.38538355  0.79733914]\n",
      " [-0.5203329   0.30046564 -0.8150209 ]\n",
      " [ 0.39399797  0.16670114  0.4062907 ]\n",
      " [-0.6391754   0.8460203   0.5266966 ]\n",
      " [ 0.41124135  0.66347724 -0.0210759 ]]\n",
      "rnn/basic_rnn_cell/bias:0 [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "### 단일cell\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(777) # 난수 값 고정 \n",
    "\n",
    "tf_inputs = tf.constant(inputs,dtype=tf.float32)\n",
    "\n",
    "##### 출력 데이터 : 1 행 3열 \n",
    "rnn_cell=tf.nn.rnn_cell.BasicRNNCell(num_units=3) # --> 히든 계층을 부른 박스 \n",
    "# 동작을 시켜야 함 정적이든 동적이든 \n",
    "outputs,state=tf.nn.dynamic_rnn(cell=rnn_cell,dtype=tf.float32,inputs=tf_inputs)# 두개의 결과 값이 나옴\n",
    "print(outputs)\n",
    "print(state)\n",
    "\n",
    "print('\\n Weights')\n",
    "for w in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES):\n",
    "    print(w)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    outputs_run,state_run = sess.run([outputs,state])\n",
    "    \n",
    "    print('output values')\n",
    "    print(outputs_run)\n",
    "    \n",
    "    print('Wnstate value')\n",
    "    print(state_run)\n",
    "    \n",
    "    print('WnWeights')\n",
    "    variable_names = [v.name for v in tf.trainable_variables()]\n",
    "    values = sess.run(variable_names)\n",
    "    for k,v in zip(variable_names,values):\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8d5c47",
   "metadata": {},
   "source": [
    "### (2) 다중 cell 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db8927b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I work at google = [[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]]\n",
    "# I google at work = [[1,0,0,0],[0,0,0,1],[0,0,1,0],[0,1,0,0]]\n",
    "\n",
    "inputs = np.array([\n",
    "    [[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],\n",
    "    [[1,0,0,0],[0,0,0,1],[0,0,1,0],[0,1,0,0]]\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7955af8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_33468/3474292658.py:4: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_33468/3474292658.py:5: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_33468/3474292658.py:10: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_33468/3474292658.py:12: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(2, 4, 3), dtype=float32)\n",
      "---------------------------------------------------------\n",
      "Tensor(\"rnn/while/Exit_3:0\", shape=(2, 3), dtype=float32)\n",
      "\n",
      " Weights\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_33468/3474292658.py:19: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_33468/3474292658.py:19: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "<tf.Variable 'rnn/basic_rnn_cell/kernel:0' shape=(7, 3) dtype=float32_ref>\n",
      "<tf.Variable 'rnn/basic_rnn_cell/bias:0' shape=(3,) dtype=float32_ref>\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(777) # 난수 값 고정 \n",
    "\n",
    "tf_inputs = tf.constant(inputs,dtype=tf.float32)\n",
    "\n",
    "##### 출력 데이터 : 1 행 3열 \n",
    "rnn_cell=tf.nn.rnn_cell.BasicRNNCell(num_units=3) # --> 히든 계층을 부른 박스 \n",
    "# 동작을 시켜야 함 정적이든 동적이든 \n",
    "outputs,state=tf.nn.dynamic_rnn(cell=rnn_cell,dtype=tf.float32,inputs=tf_inputs)# 두개의 결과 값이 나옴\n",
    "\n",
    "print(outputs)\n",
    "print('---------------------------------------------------------')\n",
    "print(state) # 입력의 갯수, 출력의 갯수\n",
    "\n",
    "print('\\n Weights')\n",
    "for w in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES):\n",
    "    print(w)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8c1a1e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output values\n",
      "[[[-0.50944704  0.33166462  0.6126557 ]\n",
      "  [-0.20793891  0.24406303 -0.75278705]\n",
      "  [-0.06346128 -0.52844936  0.68356085]\n",
      "  [-0.36491966  0.8857268  -0.02324395]]\n",
      "\n",
      " [[-0.50944704  0.33166462  0.6126557 ]\n",
      "  [-0.30707452  0.62735885  0.21719742]\n",
      "  [ 0.5043804  -0.14038289  0.3744523 ]\n",
      "  [-0.11641277  0.70696247 -0.7512605 ]]]\n",
      "Wnstate value\n",
      "[[-0.36491966  0.8857268  -0.02324395]\n",
      " [-0.11641277  0.70696247 -0.7512605 ]]\n",
      "WnWeights\n",
      "rnn/basic_rnn_cell/kernel:0 [[-0.56198275  0.34469748  0.7131618 ]\n",
      " [-0.4653999   0.2687447  -0.7289769 ]\n",
      " [ 0.35240245  0.14910203  0.36339748]\n",
      " [-0.57169586  0.7567036   0.47109187]\n",
      " [ 0.3678255   0.5934322  -0.01885086]\n",
      " [ 0.31208777 -0.40880746  0.22867584]\n",
      " [ 0.5521256   0.682691   -0.5481483 ]]\n",
      "rnn/basic_rnn_cell/bias:0 [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    outputs_run,state_run = sess.run([outputs,state])\n",
    "    \n",
    "    print('output values')\n",
    "    print(outputs_run)\n",
    "    \n",
    "    print('Wnstate value')\n",
    "    print(state_run)\n",
    "    \n",
    "    print('WnWeights')\n",
    "    variable_names = [v.name for v in tf.trainable_variables()]\n",
    "    values = sess.run(variable_names)\n",
    "    for k,v in zip(variable_names,values):\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48fb936",
   "metadata": {},
   "source": [
    "### (3) 'hihello'문장 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e82367d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
    "\n",
    "x_one_hot = [[\n",
    "    [1, 0, 0, 0, 0],  # h 0\n",
    "    [0, 1, 0, 0, 0],  # i 1\n",
    "    [1, 0, 0, 0, 0],  # h 0\n",
    "    [0, 0, 1, 0, 0],  # e 2\n",
    "    [0, 0, 0, 1, 0],  # l 3\n",
    "    [0, 0, 0, 1, 0]   # l 3\n",
    "]]\n",
    "\n",
    "y_data = [[1, 0, 2, 3, 3, 4]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26cae07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### parameter\n",
    "sequence_len = 6\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97f1170f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_27488/1905110426.py:4: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### 입출력 준비 \n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, sequence_len, num_classes])\n",
    "y = tf.placeholder(tf.int32, shape=[None, sequence_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29bf2e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(?, 6, 5), dtype=float32)\n",
      "Tensor(\"rnn/while/Exit_3:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##### rnn 모델 \n",
    "cell = tf.contrib.rnn.BasicRNNCell(num_units=num_classes)\n",
    "outputs, state = tf.nn.dynamic_rnn(cell=cell, inputs=X, dtype=tf.float32)\n",
    "print(outputs)\n",
    "print(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdea28ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##### 평면화(Flat Layer)\n",
    "X_for_fc = tf.reshape(outputs,[-1,num_classes])\n",
    "print(X_for_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb984ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_27488/905658070.py:10: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### FC Layer\n",
    "\n",
    "outputs = tf.contrib.layers.fully_connected(inputs=X_for_fc, num_outputs=10, activation_fn=None)\n",
    "outputs = tf.contrib.layers.fully_connected(inputs=outputs, num_outputs=num_classes, activation_fn=None)\n",
    "#print(outputs)\n",
    "\n",
    "outputs = tf.reshape(outputs, [1, sequence_len, num_classes])\n",
    "W = tf.ones([1, sequence_len])\n",
    "cost = tf.reduce_mean(tf.contrib.seq2seq.sequence_loss(logits=outputs, targets=y, weights=W))\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6432c5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_27488/1126891603.py:6: The name tf.arg_max is deprecated. Please use tf.argmax instead.\n",
      "\n",
      "0 1.4986173 예측값 : [[3 3 2 3 3 3]] 정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "1 1.0085273 예측값 : [[1 0 2 3 3 3]] 정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "2 0.6378594 예측값 : [[1 0 2 3 3 1]] 정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "3 0.4264063 예측값 : [[1 0 2 3 3 4]] 정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "4 0.2296506 예측값 : [[1 0 2 3 3 4]] 정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "5 0.13723554 예측값 : [[1 0 2 3 3 4]] 정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "6 0.08035306 예측값 : [[1 0 2 3 3 4]] 정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "7 0.038433924 예측값 : [[1 0 2 3 3 4]] 정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "8 0.016992657 예측값 : [[1 0 2 3 3 4]] 정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "9 0.009578231 예측값 : [[1 0 2 3 3 4]] 정답 : [[1, 0, 2, 3, 3, 4]]\n",
      "결과: i,h,e,l,l,o\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(10):\n",
    "        _,c=sess.run([train,cost],feed_dict={X:x_one_hot,y:y_data})\n",
    "        preds=sess.run(tf.arg_max(outputs,2),feed_dict={X:x_one_hot})\n",
    "        print(i,c,'예측값 :',preds,'정답 :',y_data)\n",
    "        \n",
    "    ##### 숫자로 된 것을 문자로 다시 복원해서 \n",
    "    result = [idx2char[c] for c in np.squeeze(preds)]\n",
    "    print('결과:',','.join(result))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77620c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 숫자로 된 것을 문자로 다시 복원해서 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e603c7d",
   "metadata": {},
   "source": [
    "### (4) 좀 더 긴 문자으로 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7464703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['l', 'a', 'w', 'o', 'u', 't', 'i', 'h', ' ', 'Y', 'v', 'e']\n",
      "{'l': 0, 'a': 1, 'w': 2, 'o': 3, 'u': 4, 't': 5, 'i': 6, 'h': 7, ' ': 8, 'Y': 9, 'v': 10, 'e': 11}\n",
      "[8, 9, 3, 4, 8, 2, 6, 0, 0, 8, 7, 1, 10, 11, 8, 5, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "# sample = ' You will have to submit to your fate wheather you will or not'\n",
    "sample = ' You will have to '\n",
    "\n",
    "# 단어 사전 부터 만들기 \n",
    "idx2char = list(set(sample))\n",
    "print(idx2char)\n",
    "\n",
    "# 문자를 숫자로 \n",
    "char2idx = {c:i for i,c in enumerate(idx2char)}\n",
    "print(char2idx)\n",
    "\n",
    "# 숫자로만 \n",
    "sample_idx = [char2idx[c] for c in sample ]\n",
    "print(sample_idx)\n",
    "\n",
    "# 입력 데이터 \n",
    "X_data = [sample_idx[:-1]]\n",
    "y_data = [sample_idx[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37dcf83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####parameter\n",
    "sequence_len = len(sample)-1\n",
    "num_classes = len(idx2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e37b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 입출력준비\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X= tf.placeholder(tf.int32, shape=[None, sequence_len])\n",
    "y= tf.placeholder(tf.int32, shape=[None, sequence_len])\n",
    "\n",
    "x_one_hot=tf.one_hot(X,num_classes)\n",
    "# 텐서플로 one_hot은 차원을 늘려줌 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e7c0f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/transpose_1:0\", shape=(?, 17, 12), dtype=float32)\n",
      "Tensor(\"rnn/while/Exit_3:0\", shape=(?, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 모델 \n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(num_units=num_classes)\n",
    "outputs, state = tf.nn.dynamic_rnn(cell=cell, inputs=x_one_hot, dtype=tf.float32)\n",
    "print(outputs)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ddd1b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.ones([1, sequence_len])\n",
    "cost = tf.reduce_mean(tf.contrib.seq2seq.sequence_loss(logits=outputs, targets=y, weights=W))\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f09ed550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 2.4575086\n",
      "--------------------------------------\n",
      "100 cost: 0.958887\n",
      "--------------------------------------\n",
      "200 cost: 0.94848007\n",
      "--------------------------------------\n",
      "300 cost: 0.9444304\n",
      "--------------------------------------\n",
      "400 cost: 0.94216704\n",
      "--------------------------------------\n",
      "결과: Y,o,u, ,w,i,l, , ,h,a,v,e, ,t,o, \n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(500):\n",
    "        _,c=sess.run([train,cost],feed_dict={X:X_data,y:y_data})\n",
    "        preds=sess.run(tf.arg_max(outputs,2),feed_dict={X:X_data})\n",
    "        \n",
    "        if i %100==0:\n",
    "            print(i,'cost:',c)                      \n",
    "#             print('예측값 :',preds)\n",
    "#             print('정답 :',y_data)\n",
    "            print('--------------------------------------')\n",
    "    \n",
    "    \n",
    "       \n",
    "    ##### 숫자로 된 것을 문자로 다시 복원해서 \n",
    "    result = [idx2char[c] for c in np.squeeze(preds)]\n",
    "    print('결과:',','.join(result))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a79d060",
   "metadata": {},
   "source": [
    "## 7. LSTM(Long Short Trerm Memory)\n",
    "\n",
    "+ BPTT : Back Propagation Through Time \n",
    "    - Gradient Vanishing \n",
    "    - Gradient Exploding\n",
    "    \n",
    "+ http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "855d8f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.09927537]]]\n",
      "[[0.09927537]]\n",
      "[[0.18134572]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "inputs= np.array([[[1,0]]])\n",
    "\n",
    "tf_inputs =tf.constant(inputs,dtype=tf.float32)\n",
    "cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=1)\n",
    "outputs,states=tf.nn.dynamic_rnn(cell=cell,dtype=tf.float32,inputs=tf_inputs)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    outputs_run,state_run=sess.run([outputs,states])\n",
    "    \n",
    "    print(outputs_run)\n",
    "    print(state_run.h)\n",
    "    print(state_run.c)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d13c01",
   "metadata": {},
   "source": [
    "### (1) 실습1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08dcbe2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dishplace is located in sunnyvale downtown the...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>service can be slower during busy hours but ou...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>portions are huge both french toast and their ...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we started with apps going the chicken and waf...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the biscuits and gravy was too salty two peopl...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the garlic fries were a great starter (and a h...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>our meal was excellent i had the pasta ai form...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what i enjoy most about palo alto is so many r...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the drinks came out fairly quickly a good two ...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>despite the not so good burger the service was...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the four reigning major champions simona halep...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the briton was seeded nn7 here last year befor...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stephens surged her way back from injury in st...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>when it came to england chances in the world c...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the team that eliminated russia – croatia – al...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>the perseyside outfit finished in fourth place...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>liverpool fc will return to premier league act...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>alisson signed for liverpool fc from as roma t...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>but the rankings during that run-in to new yor...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>then came the oh-so-familiar djokovic-nadal no...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            paragraph category\n",
       "0   dishplace is located in sunnyvale downtown the...     food\n",
       "1   service can be slower during busy hours but ou...     food\n",
       "2   portions are huge both french toast and their ...     food\n",
       "3   we started with apps going the chicken and waf...     food\n",
       "4   the biscuits and gravy was too salty two peopl...     food\n",
       "5   the garlic fries were a great starter (and a h...     food\n",
       "6   our meal was excellent i had the pasta ai form...     food\n",
       "7   what i enjoy most about palo alto is so many r...     food\n",
       "8   the drinks came out fairly quickly a good two ...     food\n",
       "9   despite the not so good burger the service was...     food\n",
       "10  the four reigning major champions simona halep...   sports\n",
       "11  the briton was seeded nn7 here last year befor...   sports\n",
       "12  stephens surged her way back from injury in st...   sports\n",
       "13  when it came to england chances in the world c...   sports\n",
       "14  the team that eliminated russia – croatia – al...   sports\n",
       "15  the perseyside outfit finished in fourth place...   sports\n",
       "16  liverpool fc will return to premier league act...   sports\n",
       "17  alisson signed for liverpool fc from as roma t...   sports\n",
       "18  but the rankings during that run-in to new yor...   sports\n",
       "19  then came the oh-so-familiar djokovic-nadal no...   sports"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### 데이터 준비\n",
    "\n",
    "paragraph_dict_list = [\n",
    "         {'paragraph': 'dishplace is located in sunnyvale downtown there is parking around the area but it can be difficult to find during peak business hours my sisters and i came to this place for dinner on a weekday they were really busy so i highly recommended making reservations unless you have the patience to wait', 'category': 'food'},\n",
    "         {'paragraph': 'service can be slower during busy hours but our waiter was courteous and help gave some great entree recommendations', 'category': 'food'},\n",
    "         {'paragraph': 'portions are huge both french toast and their various omelettes are really good their french toast is probably 1.5x more than other brunch places great place to visit if you are hungry and dont want to wait 1 hour for a table', 'category': 'food'},\n",
    "         {'paragraph': 'we started with apps going the chicken and waffle slides and chicken nachos the sliders were amazing and the nachos were good too maybe by themselves the nachos would have scored better but after those sliders they were up against some tough competition', 'category': 'food'},\n",
    "         {'paragraph': 'the biscuits and gravy was too salty two people in my group had the gravy and all thought it was too salty my hubby ordered a side of double egg and it was served on two small plates who serves eggs to one person on separate plates we commented on that when it was delivered and even the server laughed and said she doesnt know why the kitchen does that presentation of food is important and they really missed on this one', 'category': 'food'},\n",
    "         {'paragraph': 'the garlic fries were a great starter (and a happy hour special) the pancakes looked and tasted great and were a fairly generous portion', 'category': 'food'},\n",
    "         {'paragraph': 'our meal was excellent i had the pasta ai formaggi which was so rich i didnt dare eat it all although i certainly wanted to excellent flavors with a great texture contrast between the soft pasta and the crisp bread crumbs too much sauce for me but a wonderful dish', 'category': 'food'},\n",
    "         {'paragraph': 'what i enjoy most about palo alto is so many restaurants have dog-friendly seating outside i had bookmarked italico from when they first opened about a 1.5 years ago and was jonesing for some pasta so time to finally knock that bookmark off', 'category': 'food'},\n",
    "         {'paragraph': 'the drinks came out fairly quickly a good two to three minutes after the orders were taken i expected my iced tea to taste a bit more sweet but this was straight up green tea with ice in it not to complain of course but i was pleasantly surprised', 'category': 'food'},\n",
    "         {'paragraph': 'despite the not so good burger the service was so slow the restaurant wasnt even half full and they took very long from the moment we got seated to the time we left it was almost 2 hours we thought that it would be quick since we ordered as soon as we sat down my coworkers did seem to enjoy their beef burgers for those who eat beef however i will not be returning it is too expensive and extremely slow service', 'category': 'food'},\n",
    "    \n",
    "         {'paragraph': 'the four reigning major champions simona halep caroline wozniacki angelique kerber and defending us open champion sloane stephens could make a case for being the quartet most likely to succeed especially as all but stephens has also enjoyed the no1 ranking within the last 14 months as they prepare for their gruelling new york campaigns they currently hold the top four places in the ranks', 'category': 'sports'},\n",
    "         {'paragraph': 'the briton was seeded nn7 here last year before a slump in form and confidence took her down to no46 after five first-round losses but there have been signs of a turnaround including a victory over a sub-par serena williams in san jose plus wins against jelena ostapenko and victoria azarenka in montreal. konta pulled out of new haven this week with illness but will hope for good things where she first scored wins in a major before her big breakthroughs to the semis in australia and wimbledon', 'category': 'sports'},\n",
    "         {'paragraph': 'stephens surged her way back from injury in stunning style to win her first major here last year—and ranked just no83 she has since proved what a big time player she is winning the miami title via four fellow major champions then reaching the final at the french open back on north american hard courts she ran to the final in montreal only just edged out by halep she has also avoided many of the big names in her quarter—except for wild card azarenka as a possible in the third round', 'category': 'sports'},\n",
    "         {'paragraph': 'when it came to england chances in the world cup it would be fair to say that most fans had never been more pessimistic than they were this year after enduring years of truly dismal performances at major tournaments – culminating in the 2014 event where they failed to win any of their three group games and finished in bottom spot those results led to the resignation of manager roy hodgson', 'category': 'sports'},\n",
    "         {'paragraph': 'the team that eliminated russia – croatia – also improved enormously during the tournament before it began their odds were 33/1 but they played with real flair and star players like luka modric ivan rakitic and ivan perisic showed their quality on the world stage having displayed their potential by winning all three of their group stage games croatia went on to face difficult tests like the semi-final against england', 'category': 'sports'},\n",
    "         {'paragraph': 'the perseyside outfit finished in fourth place in the premier league table and without a trophy last term after having reached the champions league final before losing to real madrid', 'category': 'sports'},\n",
    "         {'paragraph': 'liverpool fc will return to premier league action on saturday lunchtime when they travel to leicester city in the top flight as they look to make it four wins in a row in the league', 'category': 'sports'},\n",
    "         {'paragraph': 'alisson signed for liverpool fc from as roma this summer and the brazilian goalkeeper has helped the reds to keep three clean sheets in their first three premier league games', 'category': 'sports'},\n",
    "         {'paragraph': 'but the rankings during that run-in to new york hid some very different undercurrents for murray had struggled with a hip injury since the clay swing and had not played a match since losing his quarter-final at wimbledon and he would pull out of the us open just two days before the tournament began—too late however to promote nederer to the no2 seeding', 'category': 'sports'},\n",
    "         {'paragraph': 'then came the oh-so-familiar djokovic-nadal no-quarter-given battle for dominance in the thiadal more than once pulled off a reverse smash and had his chance to seal the tie-break but it was djokovic serving at 10-9 who dragged one decisive error from nadal for a two-sets lead', 'category': 'sports'}\n",
    "]\n",
    "    \n",
    "#     스포츠와 관련인가 아닌가 구분 \n",
    "df=pd.DataFrame(paragraph_dict_list)\n",
    "df=df[['paragraph','category']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8dae92",
   "metadata": {},
   "source": [
    "#### 1) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aeb475e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530\n",
      "['dishplace', 'is', 'located', 'in', 'sunnyvale', 'downtown', 'there', 'is', 'parking', 'around', 'the', 'area', 'but', 'it', 'can', 'be', 'difficult', 'to', 'find', 'during', 'peak', 'business', 'hours', 'my', 'sisters', 'and', 'i', 'came', 'to', 'this', 'place', 'for', 'dinner', 'on', 'a', 'weekday', 'they', 'were', 'really', 'busy', 'so', 'i', 'highly', 'recommended', 'making', 'reservations', 'unless', 'you', 'have', 'the', 'patience', 'to', 'wait', 'service', 'can', 'be', 'slower', 'during', 'busy', 'hours', 'but', 'our', 'waiter', 'was', 'courteous', 'and', 'help', 'gave', 'some', 'great', 'entree', 'recommendations', 'portions', 'are', 'huge', 'both', 'french', 'toast', 'and', 'their', 'various', 'omelettes', 'are', 'really', 'good', 'their', 'french', 'toast', 'is', 'probably', '1.5x', 'more', 'than', 'other', 'brunch', 'places', 'great', 'place', 'to', 'visit', 'if', 'you', 'are', 'hungry', 'and', 'dont', 'want', 'to', 'wait', '1', 'hour', 'for', 'a', 'table', 'we', 'started', 'with', 'apps', 'going', 'the', 'chicken', 'and', 'waffle', 'slides', 'and', 'chicken', 'nachos', 'the', 'sliders', 'were', 'amazing', 'and', 'the', 'nachos', 'were', 'good', 'too', 'maybe', 'by', 'themselves', 'the', 'nachos', 'would', 'have', 'scored', 'better', 'but', 'after', 'those', 'sliders', 'they', 'were', 'up', 'against', 'some', 'tough', 'competition', 'the', 'biscuits', 'and', 'gravy', 'was', 'too', 'salty', 'two', 'people', 'in', 'my', 'group', 'had', 'the', 'gravy', 'and', 'all', 'thought', 'it', 'was', 'too', 'salty', 'my', 'hubby', 'ordered', 'a', 'side', 'of', 'double', 'egg', 'and', 'it', 'was', 'served', 'on', 'two', 'small', 'plates', 'who', 'serves', 'eggs', 'to', 'one', 'person', 'on', 'separate', 'plates', 'we', 'commented', 'on', 'that', 'when', 'it', 'was', 'delivered', 'and', 'even', 'the', 'server', 'laughed', 'and', 'said', 'she', 'doesnt', 'know', 'why', 'the', 'kitchen', 'does', 'that', 'presentation', 'of', 'food', 'is', 'important', 'and', 'they', 'really', 'missed', 'on', 'this', 'one', 'the', 'garlic', 'fries', 'were', 'a', 'great', 'starter', '(and', 'a', 'happy', 'hour', 'special)', 'the', 'pancakes', 'looked', 'and', 'tasted', 'great', 'and', 'were', 'a', 'fairly', 'generous', 'portion', 'our', 'meal', 'was', 'excellent', 'i', 'had', 'the', 'pasta', 'ai', 'formaggi', 'which', 'was', 'so', 'rich', 'i', 'didnt', 'dare', 'eat', 'it', 'all', 'although', 'i', 'certainly', 'wanted', 'to', 'excellent', 'flavors', 'with', 'a', 'great', 'texture', 'contrast', 'between', 'the', 'soft', 'pasta', 'and', 'the', 'crisp', 'bread', 'crumbs', 'too', 'much', 'sauce', 'for', 'me', 'but', 'a', 'wonderful', 'dish', 'what', 'i', 'enjoy', 'most', 'about', 'palo', 'alto', 'is', 'so', 'many', 'restaurants', 'have', 'dog-friendly', 'seating', 'outside', 'i', 'had', 'bookmarked', 'italico', 'from', 'when', 'they', 'first', 'opened', 'about', 'a', '1.5', 'years', 'ago', 'and', 'was', 'jonesing', 'for', 'some', 'pasta', 'so', 'time', 'to', 'finally', 'knock', 'that', 'bookmark', 'off', 'the', 'drinks', 'came', 'out', 'fairly', 'quickly', 'a', 'good', 'two', 'to', 'three', 'minutes', 'after', 'the', 'orders', 'were', 'taken', 'i', 'expected', 'my', 'iced', 'tea', 'to', 'taste', 'a', 'bit', 'more', 'sweet', 'but', 'this', 'was', 'straight', 'up', 'green', 'tea', 'with', 'ice', 'in', 'it', 'not', 'to', 'complain', 'of', 'course', 'but', 'i', 'was', 'pleasantly', 'surprised', 'despite', 'the', 'not', 'so', 'good', 'burger', 'the', 'service', 'was', 'so', 'slow', 'the', 'restaurant', 'wasnt', 'even', 'half', 'full', 'and', 'they', 'took', 'very', 'long', 'from', 'the', 'moment', 'we', 'got', 'seated', 'to', 'the', 'time', 'we', 'left', 'it', 'was', 'almost', '2', 'hours', 'we', 'thought', 'that', 'it', 'would', 'be', 'quick', 'since', 'we', 'ordered', 'as', 'soon', 'as', 'we', 'sat', 'down', 'my', 'coworkers', 'did', 'seem', 'to', 'enjoy', 'their', 'beef', 'burgers', 'for', 'those', 'who', 'eat', 'beef', 'however', 'i', 'will', 'not', 'be', 'returning', 'it', 'is', 'too', 'expensive', 'and', 'extremely', 'slow', 'service', 'the', 'four', 'reigning', 'major', 'champions', 'simona', 'halep', 'caroline', 'wozniacki', 'angelique', 'kerber', 'and', 'defending', 'us', 'open', 'champion', 'sloane', 'stephens', 'could', 'make', 'a', 'case', 'for', 'being', 'the', 'quartet', 'most', 'likely', 'to', 'succeed', 'especially', 'as', 'all', 'but', 'stephens', 'has', 'also', 'enjoyed', 'the', 'no1', 'ranking', 'within', 'the', 'last', '14', 'months', 'as', 'they', 'prepare', 'for', 'their', 'gruelling', 'new', 'york', 'campaigns', 'they', 'currently', 'hold', 'the', 'top', 'four', 'places', 'in', 'the', 'ranks', 'the', 'briton', 'was', 'seeded', 'nn7', 'here', 'last', 'year', 'before', 'a', 'slump', 'in', 'form', 'and', 'confidence', 'took', 'her', 'down', 'to', 'no46', 'after', 'five', 'first-round', 'losses', 'but', 'there', 'have', 'been', 'signs', 'of', 'a', 'turnaround', 'including', 'a', 'victory', 'over', 'a', 'sub-par', 'serena', 'williams', 'in', 'san', 'jose', 'plus', 'wins', 'against', 'jelena', 'ostapenko', 'and', 'victoria', 'azarenka', 'in', 'montreal.', 'konta', 'pulled', 'out', 'of', 'new', 'haven', 'this', 'week', 'with', 'illness', 'but', 'will', 'hope', 'for', 'good', 'things', 'where', 'she', 'first', 'scored', 'wins', 'in', 'a', 'major', 'before', 'her', 'big', 'breakthroughs', 'to', 'the', 'semis', 'in', 'australia', 'and', 'wimbledon', 'stephens', 'surged', 'her', 'way', 'back', 'from', 'injury', 'in', 'stunning', 'style', 'to', 'win', 'her', 'first', 'major', 'here', 'last', 'year—and', 'ranked', 'just', 'no83', 'she', 'has', 'since', 'proved', 'what', 'a', 'big', 'time', 'player', 'she', 'is', 'winning', 'the', 'miami', 'title', 'via', 'four', 'fellow', 'major', 'champions', 'then', 'reaching', 'the', 'final', 'at', 'the', 'french', 'open', 'back', 'on', 'north', 'american', 'hard', 'courts', 'she', 'ran', 'to', 'the', 'final', 'in', 'montreal', 'only', 'just', 'edged', 'out', 'by', 'halep', 'she', 'has', 'also', 'avoided', 'many', 'of', 'the', 'big', 'names', 'in', 'her', 'quarter—except', 'for', 'wild', 'card', 'azarenka', 'as', 'a', 'possible', 'in', 'the', 'third', 'round', 'when', 'it', 'came', 'to', 'england', 'chances', 'in', 'the', 'world', 'cup', 'it', 'would', 'be', 'fair', 'to', 'say', 'that', 'most', 'fans', 'had', 'never', 'been', 'more', 'pessimistic', 'than', 'they', 'were', 'this', 'year', 'after', 'enduring', 'years', 'of', 'truly', 'dismal', 'performances', 'at', 'major', 'tournaments', '–', 'culminating', 'in', 'the', '2014', 'event', 'where', 'they', 'failed', 'to', 'win', 'any', 'of', 'their', 'three', 'group', 'games', 'and', 'finished', 'in', 'bottom', 'spot', 'those', 'results', 'led', 'to', 'the', 'resignation', 'of', 'manager', 'roy', 'hodgson', 'the', 'team', 'that', 'eliminated', 'russia', '–', 'croatia', '–', 'also', 'improved', 'enormously', 'during', 'the', 'tournament', 'before', 'it', 'began', 'their', 'odds', 'were', '33/1', 'but', 'they', 'played', 'with', 'real', 'flair', 'and', 'star', 'players', 'like', 'luka', 'modric', 'ivan', 'rakitic', 'and', 'ivan', 'perisic', 'showed', 'their', 'quality', 'on', 'the', 'world', 'stage', 'having', 'displayed', 'their', 'potential', 'by', 'winning', 'all', 'three', 'of', 'their', 'group', 'stage', 'games', 'croatia', 'went', 'on', 'to', 'face', 'difficult', 'tests', 'like', 'the', 'semi-final', 'against', 'england', 'the', 'perseyside', 'outfit', 'finished', 'in', 'fourth', 'place', 'in', 'the', 'premier', 'league', 'table', 'and', 'without', 'a', 'trophy', 'last', 'term', 'after', 'having', 'reached', 'the', 'champions', 'league', 'final', 'before', 'losing', 'to', 'real', 'madrid', 'liverpool', 'fc', 'will', 'return', 'to', 'premier', 'league', 'action', 'on', 'saturday', 'lunchtime', 'when', 'they', 'travel', 'to', 'leicester', 'city', 'in', 'the', 'top', 'flight', 'as', 'they', 'look', 'to', 'make', 'it', 'four', 'wins', 'in', 'a', 'row', 'in', 'the', 'league', 'alisson', 'signed', 'for', 'liverpool', 'fc', 'from', 'as', 'roma', 'this', 'summer', 'and', 'the', 'brazilian', 'goalkeeper', 'has', 'helped', 'the', 'reds', 'to', 'keep', 'three', 'clean', 'sheets', 'in', 'their', 'first', 'three', 'premier', 'league', 'games', 'but', 'the', 'rankings', 'during', 'that', 'run-in', 'to', 'new', 'york', 'hid', 'some', 'very', 'different', 'undercurrents', 'for', 'murray', 'had', 'struggled', 'with', 'a', 'hip', 'injury', 'since', 'the', 'clay', 'swing', 'and', 'had', 'not', 'played', 'a', 'match', 'since', 'losing', 'his', 'quarter-final', 'at', 'wimbledon', 'and', 'he', 'would', 'pull', 'out', 'of', 'the', 'us', 'open', 'just', 'two', 'days', 'before', 'the', 'tournament', 'began—too', 'late', 'however', 'to', 'promote', 'nederer', 'to', 'the', 'no2', 'seeding', 'then', 'came', 'the', 'oh-so-familiar', 'djokovic-nadal', 'no-quarter-given', 'battle', 'for', 'dominance', 'in', 'the', 'thiadal', 'more', 'than', 'once', 'pulled', 'off', 'a', 'reverse', 'smash', 'and', 'had', 'his', 'chance', 'to', 'seal', 'the', 'tie-break', 'but', 'it', 'was', 'djokovic', 'serving', 'at', '10-9', 'who', 'dragged', 'one', 'decisive', 'error', 'from', 'nadal', 'for', 'a', 'two-sets', 'lead']\n"
     ]
    }
   ],
   "source": [
    "##### 단어를 분리한뒤 중복된 단어를 제거 \n",
    "word_list = []\n",
    "\n",
    "for data in df[\"paragraph\"]:\n",
    "    word_list.append(data.split(\" \"))\n",
    "    \n",
    "word = []\n",
    "for i in word_list:\n",
    "    for j in i:\n",
    "        word.append(j)\n",
    "        \n",
    "print(len(set(word)))\n",
    "print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4127f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "5     None\n",
       "6     None\n",
       "7     None\n",
       "8     None\n",
       "9     None\n",
       "10    None\n",
       "11    None\n",
       "12    None\n",
       "13    None\n",
       "14    None\n",
       "15    None\n",
       "16    None\n",
       "17    None\n",
       "18    None\n",
       "19    None\n",
       "Name: paragraph, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results= set()\n",
    "df['paragraph']\n",
    "# split은 문자열 --> 문자열로 바꿔줘야 스플릿 가능 \n",
    "df['paragraph'].str.split('').apply(results.update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bae0e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '',\n",
       " 1: 'f',\n",
       " 2: 'v',\n",
       " 3: '8',\n",
       " 4: 'b',\n",
       " 5: '.',\n",
       " 6: '/',\n",
       " 7: 'c',\n",
       " 8: ')',\n",
       " 9: 'h',\n",
       " 10: 's',\n",
       " 11: '–',\n",
       " 12: '3',\n",
       " 13: 'r',\n",
       " 14: 'u',\n",
       " 15: '7',\n",
       " 16: '4',\n",
       " 17: 'w',\n",
       " 18: 'n',\n",
       " 19: '9',\n",
       " 20: 'x',\n",
       " 21: '—',\n",
       " 22: 'q',\n",
       " 23: 'd',\n",
       " 24: 'm',\n",
       " 25: '5',\n",
       " 26: ' ',\n",
       " 27: 'k',\n",
       " 28: '1',\n",
       " 29: 'g',\n",
       " 30: '(',\n",
       " 31: 'l',\n",
       " 32: 'e',\n",
       " 33: 'a',\n",
       " 34: 'y',\n",
       " 35: 'j',\n",
       " 36: '2',\n",
       " 37: 'z',\n",
       " 38: 'p',\n",
       " 39: '0',\n",
       " 40: 'o',\n",
       " 41: 't',\n",
       " 42: '6',\n",
       " 43: 'i',\n",
       " 44: '-'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어와 숫자를 매칭해서 dict 자료형 변수 작성(idx2word)\n",
    "idx2word= dict(enumerate(results))\n",
    "idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee6bece",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bed2aac8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_33468/1371615282.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword2idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mword2idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unique_words' is not defined"
     ]
    }
   ],
   "source": [
    "word2idx = {word:num for word, num in zip(unique_words, range(len(unique_words)))}\n",
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02be8c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {v:k for k,v in idx2word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "727b095e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'f': 1,\n",
       " 'v': 2,\n",
       " '8': 3,\n",
       " 'b': 4,\n",
       " '.': 5,\n",
       " '/': 6,\n",
       " 'c': 7,\n",
       " ')': 8,\n",
       " 'h': 9,\n",
       " 's': 10,\n",
       " '–': 11,\n",
       " '3': 12,\n",
       " 'r': 13,\n",
       " 'u': 14,\n",
       " '7': 15,\n",
       " '4': 16,\n",
       " 'w': 17,\n",
       " 'n': 18,\n",
       " '9': 19,\n",
       " 'x': 20,\n",
       " '—': 21,\n",
       " 'q': 22,\n",
       " 'd': 23,\n",
       " 'm': 24,\n",
       " '5': 25,\n",
       " ' ': 26,\n",
       " 'k': 27,\n",
       " '1': 28,\n",
       " 'g': 29,\n",
       " '(': 30,\n",
       " 'l': 31,\n",
       " 'e': 32,\n",
       " 'a': 33,\n",
       " 'y': 34,\n",
       " 'j': 35,\n",
       " '2': 36,\n",
       " 'z': 37,\n",
       " 'p': 38,\n",
       " '0': 39,\n",
       " 'o': 40,\n",
       " 't': 41,\n",
       " '6': 42,\n",
       " 'i': 43,\n",
       " '-': 44}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24e5d981",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 데이터들을 숫자로 변환 \n",
    "\n",
    "def encoded_paragraph(param):\n",
    "    words = param.split()\n",
    "    encoded = []\n",
    "    \n",
    "    for w in words: \n",
    "        encoded.append([word2idx[w]])\n",
    "        \n",
    "    return encoded\n",
    "\n",
    "def encoded_catagory(param):\n",
    "    if param == 'food':\n",
    "        return [1,0]\n",
    "    else:\n",
    "        return [0,1]\n",
    "    \n",
    "# 각 문장에서 단어 갯수 파악 \n",
    "def word_cnt(param):\n",
    "    return len(param.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fc43797",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'dishplace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_33468/1650267716.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'enc_paragraph'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_paragraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4356\u001b[0m         \"\"\"\n\u001b[1;32m-> 4357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1101\u001b[1;33m                     \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1102\u001b[0m                 )\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_33468/2564763603.py\u001b[0m in \u001b[0;36mencoded_paragraph\u001b[1;34m(param)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mencoded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mencoded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'dishplace'"
     ]
    }
   ],
   "source": [
    "df['enc_paragraph']=df.paragraph.apply(encoded_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49694c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                             paragraph category enc_paragraph  \\\n",
       "0   dishplace is located in sunnyvale downtown the...     food          None   \n",
       "1   service can be slower during busy hours but ou...     food          None   \n",
       "2   portions are huge both french toast and their ...     food          None   \n",
       "3   we started with apps going the chicken and waf...     food          None   \n",
       "4   the biscuits and gravy was too salty two peopl...     food          None   \n",
       "5   the garlic fries were a great starter (and a h...     food          None   \n",
       "6   our meal was excellent i had the pasta ai form...     food          None   \n",
       "7   what i enjoy most about palo alto is so many r...     food          None   \n",
       "8   the drinks came out fairly quickly a good two ...     food          None   \n",
       "9   despite the not so good burger the service was...     food          None   \n",
       "10  the four reigning major champions simona halep...   sports          None   \n",
       "11  the briton was seeded nn7 here last year befor...   sports          None   \n",
       "12  stephens surged her way back from injury in st...   sports          None   \n",
       "13  when it came to england chances in the world c...   sports          None   \n",
       "14  the team that eliminated russia – croatia – al...   sports          None   \n",
       "15  the perseyside outfit finished in fourth place...   sports          None   \n",
       "16  liverpool fc will return to premier league act...   sports          None   \n",
       "17  alisson signed for liverpool fc from as roma t...   sports          None   \n",
       "18  but the rankings during that run-in to new yor...   sports          None   \n",
       "19  then came the oh-so-familiar djokovic-nadal no...   sports          None   \n",
       "\n",
       "   enc_catagory  seq_length  \n",
       "0        [0, 1]          53  \n",
       "1        [0, 1]          19  \n",
       "2        [0, 1]          42  \n",
       "3        [0, 1]          43  \n",
       "4        [0, 1]          82  \n",
       "5        [0, 1]          24  \n",
       "6        [0, 1]          50  \n",
       "7        [0, 1]          43  \n",
       "8        [0, 1]          49  \n",
       "9        [0, 1]          82  \n",
       "10       [0, 1]          65  \n",
       "11       [0, 1]          88  \n",
       "12       [0, 1]          91  \n",
       "13       [0, 1]          71  \n",
       "14       [0, 1]          70  \n",
       "15       [0, 1]          30  \n",
       "16       [0, 1]          35  \n",
       "17       [0, 1]          30  \n",
       "18       [0, 1]          63  \n",
       "19       [0, 1]          46  >"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['enc_catagory']=df.paragraph.apply(encoded_catagory)\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73ec9225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>category</th>\n",
       "      <th>enc_paragraph</th>\n",
       "      <th>enc_catagory</th>\n",
       "      <th>seq_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dishplace is located in sunnyvale downtown the...</td>\n",
       "      <td>food</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>service can be slower during busy hours but ou...</td>\n",
       "      <td>food</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>portions are huge both french toast and their ...</td>\n",
       "      <td>food</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we started with apps going the chicken and waf...</td>\n",
       "      <td>food</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the biscuits and gravy was too salty two peopl...</td>\n",
       "      <td>food</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paragraph category enc_paragraph  \\\n",
       "0  dishplace is located in sunnyvale downtown the...     food          None   \n",
       "1  service can be slower during busy hours but ou...     food          None   \n",
       "2  portions are huge both french toast and their ...     food          None   \n",
       "3  we started with apps going the chicken and waf...     food          None   \n",
       "4  the biscuits and gravy was too salty two peopl...     food          None   \n",
       "\n",
       "  enc_catagory  seq_length  \n",
       "0       [0, 1]          53  \n",
       "1       [0, 1]          19  \n",
       "2       [0, 1]          42  \n",
       "3       [0, 1]          43  \n",
       "4       [0, 1]          82  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['seq_length'] = df.paragraph.apply(word_cnt)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b56a0af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "##### 문장의 최대길이 \n",
    "max_word_cnt= 0 \n",
    "for row in df['paragraph']:\n",
    "    if len(row.split())>max_word_cnt:\n",
    "        max_word_cnt = len(row.split())\n",
    "        \n",
    "print(max_word_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36dd85e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_word_cnt = df['seq_length'].max() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c4faea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 문장의 길이가 91개가 안될 경우 -1로 채운다\n",
    "\n",
    "def sequence_padding(enc_param):\n",
    "    seq_len=len(enc_param)\n",
    "    \n",
    "    for i in range(seq_len,max_word_cnt):\n",
    "        enc_param.append([-1])\n",
    "        \n",
    "    return enc_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac54e26c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_33468/4096670748.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'enc_paragraph'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc_paragraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_padding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4356\u001b[0m         \"\"\"\n\u001b[1;32m-> 4357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1101\u001b[1;33m                     \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1102\u001b[0m                 )\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_33468/256631473.py\u001b[0m in \u001b[0;36msequence_padding\u001b[1;34m(enc_param)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msequence_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_param\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mseq_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_param\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_word_cnt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "df['enc_paragraph']=df.enc_paragraph.apply(sequence_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bca0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['enc_paragraph'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6eb4d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_paragraph = np.array(df.enc_paragraph.tolist())\n",
    "encoded_catagory = np.array(df.enc_catagory.tolist())\n",
    "seq_length = np.array(df.seq_length.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cb9042",
   "metadata": {},
   "source": [
    "#### 2) 모델구축 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7948348e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enc_category' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_33468/848884813.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menc_paragraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_y\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0menc_category\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'enc_category' is not defined"
     ]
    }
   ],
   "source": [
    "train_X=enc_paragraph\n",
    "train_y= enc_category\n",
    "\n",
    "print(train_X.shape,train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b47e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "\n",
    "lr = 0.001\n",
    "n_epochs=300\n",
    "\n",
    "X = tf.palceholder(tf.float32,[None,max_word_cnt,1])\n",
    "y =  tf.palceholder(tf.float32,[None,2])\n",
    "cell=tf.nn.rnn_cell.LSTMCell(num_units=64)\n",
    "tf.nn.dynamic_rnn(cell=cell, inputs=X,dtypes=tf.float32),\n",
    "sequence_length = seq_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "810d235b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'variable'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_33468/1322915484.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m##### FC Layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mW1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlayer1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\util\\module_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    191\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m       \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfmw_wrapped_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfmw_public_apis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'variable'"
     ]
    }
   ],
   "source": [
    "##### FC Layer \n",
    "\n",
    "W1= tf.variable(tf.random_normal([64,32]))\n",
    "b1 = tf.Variable(tf.random_normal([32]))\n",
    "layer1 = tf.nn.relu(tf.matmul(state.h,W1)+b1)\n",
    "\n",
    "W2= tf.variable(tf.random_normal([32,2]))\n",
    "b2 = tf.Variable(tf.random_normal([2]))\n",
    "logit = tf.matmul(layer1.h,W2)+b2\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                labels=y))\n",
    "train= tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "print(layer1)\n",
    "\n",
    "print(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f10824",
   "metadata": {},
   "outputs": [],
   "source": [
    " ### 간단히 \n",
    "# W1= tf.variable(tf.random_normal([64,32]))\n",
    "# b1 = tf.Variable(tf.random_normal([32]))\n",
    "# layer1 = tf.nn.relu(tf.matmul(state.h,W1)+b1)\n",
    "layer1=tf.layers.dense(state.h,32) # 입력값과 출력값 \n",
    "\n",
    "# W2= tf.variable(tf.random_normal([32,2]))\n",
    "# b2 = tf.Variable(tf.random_normal([2]))\n",
    "# logit = tf.matmul(layer1.h,W2)+b2\n",
    "logut=tf.layers.dense(layer1,2)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                labels=y))\n",
    "train= tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "print(layer1)\n",
    "\n",
    "print(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ac849cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_33468/2883058631.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_33468/2883058631.py\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    print(epoch,':',c,','cur_acc)\u001b[0m\n\u001b[1;37m                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        _,c=sess.run([train,cost],feed_dict={X:train_X,y:train_y})\n",
    "        \n",
    "        if epoch % 50==0:\n",
    "            preds = tf.nn.softmax(logit)\n",
    "            correct_pred=tf.equal(tf.argmax(preds,1),tf.argmax(y,1))\n",
    "            accuracy=tf.reduce_mean(tf.cast(correct_pred,'float'))\n",
    "            cur_acc=accuracy.eval({X:train_X,y:train_y})\n",
    "            print(epoch,':',c,','cur_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71ca29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de8b377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e9798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
